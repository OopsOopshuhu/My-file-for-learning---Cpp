# Redis学习笔记
redis只存k-v形式---操作就像 unordered_map  k-string
```cpp
# T支持 string list set zset hashmap
template class<T>;
unordered_map<string, T>
```
1. string
   ```cpp
   unordered_map<string, string> strings;
   ```
2. hashMap
   ```cpp
   unordered_map<string, unordered_map<string, string>> hashes;
   ```
3. List
   ```cpp
   unordered_map<string, list<string>> lists;
   ```
4. Set
   ```cpp
   unordered_map<string, unordered_set<string>> sets;
   ```
5. Sortedset-一种有序集合
   ```cpp
   unordered_map<string, skiplist<string, string>> zsets;
   ```
## 超期数据删除
1. 随机选择算法定时删除
2. 惰性删除
3. 内存淘汰策略
   * noeviction---返回错误，不会删除任何key
   * allkeys-**lru**---使用**LRU**算法删除最近最少使用的key
   * volatile-**lru**---使用**LRU**算法从设置了过期时间的键集合中删除最近最少使用的key
   * allkeys-random---从所有key随机删除
   * volatile-random---从设置了过期时间的键集合中随机删除
   * volatile-ttl---从设置了过期时间的键中删除剩余时间最短的key
   * volatile-**lfu**---从配置了过期时间的键中删除使用频率最少的key
   * allkeys-**lfu**---从所有键中删除使用频率最少的键

## 缓存穿透
请求查询数据不存在，mysql白忙活了。因为不存在,redis也没法缓存，即帮不上忙，即---缓存穿透
**解决方式->布隆过滤器**或者缓存一个空串儿挡一下
* 布隆过滤器
  

## 缓存击穿
mysql摸鱼，一下怼过来一堆请求，直接打穿服务器。其实这个热点数据因为过期被redis删掉了。没想到来一大波对这个数据的请求。如果不及时缓存这个数据，可能会造成缓存雪崩

## 缓存雪崩
大量的网络请求，比之前的规模大的多。mysql直接崩掉。这次是一大批数据几乎同时过了有效期。因为这个时间不是redis设置的，是应用程序设置的，去找应用程序把缓存时间设置的均匀一些，至少不让大量数据集体失效。

**redis增加新功能：过期时间均匀分布+热点数据永不过期**
> 永不过期要注意在value当中包含一个逻辑的过期时间，另起一个线程，定期重建这些缓存

如果哪天redis挂了，再次启动之前缓存的数据全都没了，数据全在内存中，所以都没了

## redis 持久化存储AOF
也可以在硬盘上保存一下--->**RDB方案**
**遍历**一边所有的**数据**，全部**写入文件**中，为了节约空间，定义二进制格式，数据一个个码在一起，**生成rdb文件**。因为不能一直备份，或者没有写数据，也不用重新备份，所以提供一个**配置参数**，既可以**支持周期性备份**，也可以**避免作无用功**
```cpp
# 多个条件组合使用
save 900 1 # 900s 内有1个写入
save 300 10 # 300s 内有10个写入
save 60 1000 # 60s 内有1000个写入
```
>想了一下还是不行，需要创建一个**子进程**去做这些事，不能浪费redis的时间

>因为服务器每秒钟都要响应很多请求，上面的时间太长，会丢失很多数据。因为这个备份要遍历所有数据太贵，不适合高频执行。所以不能一次遍历全部数据。二进制日志binlog记录对数据执行更改的所有操作，像是INSET，UPDATE，DELETE等，**持久化AOF**！！！！----Append Only File

**AOF：** 把所有写入命令全部记录，生成AOF备份文件，多久写一次文件？准备一个**临时缓冲区(aof_buf)**，把要记录的命令临时先保存在这里，再择机写入文件。随着时间的推移，AOF备份文件越来越大，不仅非常占硬盘空间，复制移动加载分析都很贵，**文件压缩，AOF重写！！！！** 记录最终的数据状态，**指令合并**。还是fork出一个子进程，子进程在重写时要是redis修改了数据就会出现和重写内容不一致的情况。增加**aof_rewrite_buf重写缓冲区** 从创建重写子进程的那一刻，把后面来的写入命令也copy一份写入重写缓冲区，等子进程重写文件之后，在把重写缓冲区的命令写入新的AOF备份文件中，最后再重命名新的文件

哪天又redis又崩了，老崩也不是个办法，redis就一个服务器，怎么可能高可用。需要再找别的实例。主从模式，主节点写数据，从节点读数据，并做好数据同步，读写分离提高性能。主节点崩溃了，从节点顶上去，就能实现高可用。**主节点生成RDB备份文件和缓存的生成RDB期间修改的命令列表文件**，从节点加载完RDB后也执行一下这些命令，保证数据一致。如果主节点有数据写入、删除、修改命令，也会把这些命令通知到从节点，即**命令传播**。如果某个从节点掉线了，因为只是一会儿，主节点也不用重新把RDB重新发一份，只要在主节点准备一个复制积压缓冲区，后面在传播命令的时候，除了同步给从节点，也往自己的缓冲区写一份，下次再掉线，直接把最近的命令发给从节点即可。因为不确定哪些数据要传，所有弄一个**游标->复制偏移量**，从0开始，随着数据复制和同步，所有节点一起更新，后面只要比较各自偏移量就知道哪些数据要传了。redis-check-aof

## 哨兵Sentinel
哪天主节点挂了，需要手动把从节点升级为主节点，不够智能。选一个管理员，不用负责数据读写，只用来统筹协调------>**哨兵Sentinel**。管理员挂了，不行，多找几个管理员。

哨兵每隔10s用info命令问候一下主节点。主节点反馈有哪些从节点。
哨兵每隔1s PING一下其他小伙伴，如果在设置的时间里没有收到回复，多半是跪了...开始启动故障转移，但是不知是否真的挂掉了。

当管理员发现主节点掉线，判定为**主观下线**，然后和其他管理员沟通，如果都判定为下线，判定为**客观下线**。

确定挂掉，执行故障转移
## 故障转移
1. 选择新主节点
2. 从节点从新主节点同步数据
3. 旧主节点改为从节点

怎么选择新主节点？
1. 设置优先级
2. 参考复制偏移量，越大的数据越全

每个节点保存了全部数据，数据量多了怎么办？

## redis集群
把所有节点的内存空间拼起来，每个节点负责一部分数据，合体进化成一个大的缓存服务器。抄袭TCP三次握手，提出握手协议。要加入集群，得有介绍人，团队里任何成员都行。只要告诉成员IP和端口，就给新对象发送一个MEET信息，对方会一个PONG信息同意入伙，再给他一个PING信息，三次握手完成！。

数据存储的公平问题，学习哈希表的方法，一共划分16384个哈希桶，称为**槽位Slot**，按照每个redis能力大小分配槽位。能力越大责任越大。

数据读写的时候，对key进行哈希计算---槽位计算，映射到哪个槽就由谁负责。为了压缩数据空间，每个槽用一个bit来表示，自己负责位就是1,否则就是0。一共16384个bit 2048个字节，传输起来轻便快捷，用来告知其他redis自己的槽位信息的时候用。但也不能总去看谁的那一位是1.于是决定用空间换时间

准备一个超大的数组来存储每个槽由哪个节点负责
```cpp
struct clusterNode *slots[16384/8]
```
每到数据访问的时候就能快速知道由谁来负责。每个槽位都有人负责，集群状态为上线状态，否则为下线。

## 正式工作
和原来不同的是，数据读写的时候多一个步骤，得先检查数据是不是由自己负责，如果是，就处理，不是就返回MOVED给请求端，同时告知槽号、IP和端口。

如果集群哪天哪个redis挂了，就完了

在所有redis成员中，至少得有一个backup。找到原来的一帮从节点，平时当每个redis成员的从节点，继续复制数据

集群工作+主从复制模式
不仅高可用，数据容量也大大提升，不够用了也有办法扩容

---
## redis 基础知识补充
### 1. 通用命令
1. SQL---结构化的、关系型数据库，查询语句固定，满足ACID
   Redis---非结构化的、无关联数据库，get user:key，无法全部满足ACID，BASE满足
   MongDB---非结构化的、无关联数据库，db.users.find({_id: ket})

   内存存储，查询性能高。NoSQL考虑到数据拆分需求，插入数据的时候都会根据数据唯一的标识进行hash运算，根据运算结果判断存在哪个节点，从而实现数据拆分，天然支持水平扩展（实现分布式数据库）
2. 单线程，每个命令串行执行，具有原子性
  低延迟，速度快（**基于内存**、IO多路复用、良好的编码）
  支持数据持久化
  支持主从集群，分片集群（数据拆分存到节点，水平扩展）
3. 语句指令
   * help @group---查询指令帮助
   * keys---查看符合模板的所有key-----生产环境下不建议keys查询，如果是集群，可以在从节点查询，不然会一直阻塞所有的请求
       > keys * ---全查
       keys a*  ---模糊查询
   * del key---删除，可以接多个
   * mset k1 v1 k2 v2---批量插入
   * exists---判断key存在
   * expire---设置key有效期，到了自动删除
   * ttl---查看key剩余有效期
### 2. string命令
* set---添加或者修改
* get---根据key获得val
* mget---批量获取
* incr---让一个整型的val自增1
* incrby---自增并指定步长，原子递增
* incrbyfloat---浮点型自增并指定步长
* setnx---添加一个string类键值对，前提是不存在
* setex---添加string键值对并指定有效期
> redis 的 key 允许有多个单词形成层级结构，用 ':' 隔开，如 项目名：业务名：类型：id
> 一个用户可以对应一个json字符串，如{"id":1, "name":"jack", "age":21}
### 3. hash命令
![](2023-02-25-17-00-08.png)
* hset key field value---添加
* hget key field
* hmset
* hmget
* hgetall---获取key中所有field和value
* hkeys---获取key中的所有field
* hvals---获取key中所有value
* hincrby---value自增，步长
* hsetnx---添加key的field值，前提不存在
### 4. list命令
> 有序，元素可以重复，插入和删除快，查询速度一般
* lpush key elemnt...---左侧插入一个或多个
* lpop key---移除并返回左侧第一个元素
* lrange key star end---返回范围内的所有元素
* blpop and brpop---在没有元素时等待指定时间，而不是返回nil
  > 应用场景：消息队列，
### 5. set命令
> 无序，元素不可重复，查找快，支持交集、并集、差集
* sadd key member...---插入一个或多个元素
* srem key member...---移除一个或多个
* scard key---返回set中元素个数
* sismember key member---是否是成员
* smembers---获取所有元素
* sinter key1 key2...---求交集
* sdiff key1 key2...---差集
* sunion key1 key2...---并集
  > 应用场景：共同好友
### 6. Sortedset命令
> 每一个元素都带有一个 score 属性，即排序标准，底层实现是跳表+hash表
> 可排序，元素不重复，查询速度快
* zadd key score member---添加一个或多个元素，如已经存在，更新score值
* zrem key member
* zscore key member---获取score
* zrank key member---获取指定元素的排名
* zcard key---元素个数
* zcount key min max---给定范围所有元素个数
* zincrby key increment member---指定元素自增，步长为increment
* zrange key min max---按照score排序后，获取范围内元素
* zrangebyscore key min max---排序后，获取范围元素
* zdiff\zinter\zunion---求差集、交集、并集
  > 默认升序，降序z+rev
  与红黑数平衡树相比，为什么用跳表？
  1 插的快，不用旋转或者保持平衡
  2 实现容易
  3 支持无锁操作


### geohash---地图，附近的商户（坐标）
> 借助Sorted Set实现，通过zset的score进行排序得到坐标附近的其他元素，通过将score还原成坐标值就可以拿到元素的原始坐标
### hyperloglog---UV统计
> 统计不重复数据，用于大数据基数统计
### bitmap---用户签到，布隆过滤器
### streams---内存版kafka
### 项目中遇到的问题
1. session 共享---tomcat集群，不共享无法找到存储的用户信息，解决方案！redis替代session

## 面试
* 网络请求过程是多线程的，而键值对的读写核心还是单线程的，所以redis是并发安全的
  而他的持久化，集群数据同步是额外的线程执行的
  > Redis的单线程指的是执行命令时的单线程
* 单线程为什么那么快
  1. 命令执行操作基于内存（主要)，内存响应时间100ns
  2. 没有线程切换开销
  3. 基于IO多路复用，非阻塞IO，提升redis的IO利用率（epoll），消息的收发不会阻塞，只有在调用的时候，就是处理的时候才会，事件驱动，reactor模型
  4. 存储结构高效，比如跳表，压缩列表，链表等等。经过hash分片算法返回定位，存储链表
* redis key过期了，为什么内存没有释放
  很多原因：
  1. 修改redis的value的时候，一定要确定这个key是否有过期时间，如果有，一定要带上过期时间，不然会永远不过期
  2. 和过期key的处理策略有关，虽然过期但不会马上删除，如惰性删除，用到的时候才会删除，或者随机删除没有删除到它
* key没设置过期时间但是被redis主动删除
  当redis已用内存超过maxmemory限定，主动清理。参考内存淘汰策略
* LRU和LFU区别
  LRU---least recently used---参考最后访问时间
  LFU---least frequently used---参考访问次数
* 删除key命令会阻塞redis吗？
  删除大量的key会发生阻塞，可以使用异步删除。先修改key，逻辑删除，再用淘汰策略删除，通过scan命令一批批清理，避免一次性删除大量数据
* 主从，哨兵，集群优缺点
* 分片算法---数据到底放在哪个节点
  hash分片算法，slot划分
* 死循环阻塞bug---randomkey。redis如果出现大量过期的key还没有删除，结果每次拿出来的都是过期的key
  如果在slave上执行randomkey，问题会更严重。slave针对过期的key不会主动删除，必须要master先删掉，再向slave发出del请求
  解决方案就是对挑key的次数进行限制
* 一次线上事故，主从切换导致缓存雪崩---主从机器时钟不一致
* RDB，AOF，混合持久化是怎么回事
  生成RDB文件两种方式 save(同步) bgsave(异步)---fork子进程
  混合---RDB快照和增量的AOF指令存在一起，写入新的AOF，redis重启先加载RDB再AOF
* 线上redis持久化策略一般如何设置
  性能要求高，master不做持久化，再某个slave开启AOF备份，每秒同步一次即可
* 主节点宕机，数据全部丢失
  master+slave模式，master没开持久化，redis使用supervisor管理，并配置进程宕机自动重启
  此时master宕机，哨兵还未发起切换，master就被supervisor自动拉起，启动后是个空实例，此时slave为了与master保持一致，也会自动清空
  此时，客户端访问redis，发现啥也没有，就会打很多请求，进一步影响缓存雪崩
  分析：此情况不应该配马上重启的功能
* 线上数据如何备份
  1. 写crontab定时调度脚本，每小时copy一份RDB或AOF到另一台机器，保留最近48小时备份
  2. 每天保留一份当日数据备份到一个目录，可以保留最近一个月的备份
  3. 每次copy备份，把太旧的给删了
* 主从复制风暴
  一主很多从，从重启，主压力很大。可以安排成树形
* 集群网络抖动导致频繁主从切换
  配置文件 cluster-node-timeout ,超时才认为挂掉，执行主从切换
* 集群为什么至少需要三个master节点。一个挂了，选举从节点为主节点
* 集群支持批量操作命令吗
  类似mset, mget 但要做一些处理，再key前面加上{XXX}，这样参数数据分片hash计算的只会是括号里的值，能确保不同的key能落到同一节点里
  > mset {user1}:1:name zhuge {user1}:1:age 18
* Lua 脚本能在集群里执行吗
  给Lua脚本的key前面加一个相同的hash tag{}
* 主从切换导致分布式锁丢失
  线程1 加锁成功，主向从异步同步数据，还没有同步成功的时候（线程1以为成功了），主节点挂了，从节点被选为新的主节点，实际上并没有那个数据，线程2 加锁新的主节点，也能加成功。之前的锁丢失了
  解决方案：想用redis实现分布锁，又想让锁不丢失---redlock
  redlock（不推荐，有主从）：半数以上redis加锁成功，加锁，否则锁回滚。高可用架构不是加从节点，不然依然存在问题。但如果一个redis还没持久化就被重启了（一秒一次），key就丢了。还是会出现并发安全问题
  直接设置每一条命令持久化一次，always
* redis缓存架构，及线上问题---主要在于没有设置过期时间，拿到数据就往reids里面存，然后丢进缓存里，事件常了缓存就满了。大公司一般都是冷热分离，热数据都在redis，常热数据最好不设置失效时间。最好每天查完商品都更新一下过期时间redisutil(读延期)
* redis 性能分析--- Redis 可以通过哪些机制来提高性能，当性能瓶颈发生的时候，我们又能做出哪些优化策略，最终确保业务系统的稳定运行。
  > redis常用作缓存、排行榜、计数器、 消息队列等，是电商秒杀、聊天系统等业务场景
  它不仅支持字符串，还支持不同类型的抽象数据结构，如列表、映射、集、排序集、HyperLogLogs、位图、流和空间索引

  > 设置 maxmemory 来限制使用内存大小，不然写满了内存会和磁盘频繁交换，降低性能 
  如果 AOF 的刷盘时机设置为每次写入都刷盘，由于每次写命令都需要写入文件并刷到磁盘中才会返回，当写入量很大时，会增加磁盘 IO 的负担，大大降低 Redis 的写入性能

  > 纯内存访问，IO多路复用

  > 随着业务规模的扩大，分布式架构提高性能。主从复制，设置哨兵，集群等等
* 你了解的redis？
  1. Redis是一款基于键值对的NoSQL数据库，它的值支持多种数据结构：字符串(strings)、哈希(hashes)、列表(lists)、集合(sets)、有序集合(sorted sets)等。
  2. Redis将所有的数据都存放在内存中，所以它的读写性能十分惊人，用作数据库，缓存和消息代理。
  3. Redis具有内置的复制，Lua脚本，LRU逐出，事务和不同级别的磁盘持久性，并通过Redis Sentinel和Redis Cluster自动分区提供了高可用性。
  4. Redis典型的应用场景包括：缓存、排行榜、计数器、社交网络、消息队列等
  5. 开发一套大系统，如Twitter,Youtude这样的规模，redis就是核心之一。因为支持多种数据结构，redis可以说是万金油
* 分表分库+水平拆分+MySql集群
  1. 主库的写压力出现瓶颈（行锁InnoDB取代表锁MyISAM）
  2. 分库：根据业务相关紧耦合在同一个库，对不同的数据读写进行分库（如注册信息等不改动的冷库与购物信息等热门库分开）
  3. 分表：切割表数据（例如90W条数据，id 1-30W的放在A库，30W-60W的放在B库，60W-90W的放在C库）
* redis 的 rehash
  redis在项目中时长被用来存放缓存信息，由位桶组成，随着缓存信息的增多，需要扩容，就需要对之前的键值对重新hash
  1. 分配空间再开一个hash table
  2. 维持一个索引变量，置0表示rehash开始，期间删改查在两个hash table上进行，增只在 ht[1]
  3. 直到rehash结束，rehashindex置-1表结束
   > rehash也发生在hash表收缩的时候，为的是维持负载因子的合理范围。当数据量比较大时一般参用渐近rehash
* redis 字符串实现
  SDS抽象类，实现字符串的动态扩展，因为是动态的，相比c不会溢出比较安全，也比较省时
  也可以被用作缓冲区，比如说作为AOF buffer ，或者客户端的输入buffer
* 分布式锁解决突发性热点缓存并发重建
  冷数据变为热数据，直接击穿redis到sql
  加锁，完了把数据放到缓存，缓存重建完毕释放锁
* 分布式锁
  setnx key value --- 仅当key不存在时生效
  两个请求对同一个商品做并发重建，两个请求同时执行上面语句
  在该商品key前面加一个锁前缀作为key---lock:ID
  大公司都是基于redisson执行分布式锁
* 缓存数据库双写不一致问题
  更新数据库还未来及的缓存被别人插一脚。别人缓存好了，我才缓存好，我缓存好的，和别人后刷在数据库的数据不一致
  工作当中删除缓存一样会有这个问题
  1. 分布式锁解决---可能出现性能问题
  2. 事务机制，同步更新
  3. 先删缓存，后更库
   * 延时双删
   > 淘汰缓存，写数据库，休眠1秒再次淘汰缓存，删掉脏数据，确保请求结束，写请求可以删掉读请求的缓存脏数据。只要这个休眠时间在读的基础上稍微价格几百ms

   > 如果使用的是mysql读写分离架构，主从同步也会有时间差。A先删缓存，然后找主库更新，主库数据同步从库，但还没同步好，请求B从从库拿旧数据。redis是新数据，也是数据不一致
   解决办法是：redis没数据，如果是查库，强制指向主库查 

   > 缓存不删除，修改value为特殊值，客户端发现是特殊值，就休眠一会，再查redis，对业务有侵入
   * update和read异步串行化
    1). 异步串行化
   内部维护n个内存队列。对同一个数据的请求发送到同一个队列，每个队列对应一个线程，顺序执行队列。redis没有，扔到队列，等缓存结束再读库

        2). 读操作去重
  多个读库更新缓存请求串一个队列没意义，做过滤
  4. 先更库，后删缓存
   > 更库完成，删缓报错。将key作为消息体放到消息队列MQ，缓存里没找到，都进消息队列。队列尽量水平拆分提高并行度，缓解压力。系统收到队列消息再次删缓操作。会造成代码侵入

   > 给缓存设置一个过期时间，相当于重建

   > 热点数据设置永不过期，value写入一个逻辑过期时间，另起线程，对于逻辑上过期的key进行删除
   优化方案：订阅mysql的binlog日志对缓存操作。就是说作为中间人去拉队列的数据
* 任何的分布式锁在开发之后都需要做优化！
  压力暴增，分布式锁串行优化方案
  > case1: 读多写少
    读写锁优化！读锁和写锁分开，操作lock_key是同一把。读锁并行，读写互斥，写锁等待
  > case2: 并发重建分布式锁优化
    trylock配置等待时间，如3s内没有释放，直接抛异常，等锁的线程直接return，执行查缓存的代码
* 多级缓存解决线上集群缓存雪崩
  map(内存挡)---虽然可以，但放不下太多商品，会爆掉。分布式集群下面有缓存一致性的问题
* redis单线程模型
  基于reactor模型，采用IO多路复用机制同时监听多个Socket
  文件事件处理器结构：多个Socket, IO多路复用程序、文件事件分派器以及事件处理器
  将各个事件的socketfd 放入队列，每次取出一个给事件分配器，在传给对应的处理器，处理完之后继续
* 分布式锁底层实现？
  1. 利用setnx来保证
  2. 利用Lua脚本保证多个redis操作的原子性
  3. 考虑锁过期，需要看门狗定时任务监听锁是否续约
  4. 考虑redis挂掉的情况，红锁方式向N/2+1节点申请锁,申请到了获锁成功，就算某个节点挂掉，锁也不会被抢
* 哨兵
  1. 集群监控
  2. 消息通知
  3. 故障转移
  4. 配置中心---通知客户端新的master地址
   > 哨兵用于实现redis的高可用，本身也是分布式的，作为哨兵集群运行
   1) 判断是否宕机，需要投票
   2) 部分哨兵挂掉，哨兵集群正常工作
   3) 哨兵通常选奇数个实例，保证健壮性
   4) 哨兵+redis主从不保证数据零丢失，只保证高可用
* 基础一个名词，hash分片！！！！就可以理解redis分片以及slot
* 主从复制的核心---1. 全量复制， 2. 增量复制
* 布隆过滤器
  数据到来经过hash后也要更改filter位，其实就是做一个筛选
  优点：
   1）占用内存小
   2) 增查事件快
   3) hash函数之间没有关联
   4) 安全--不存元素本身
  缺点
   1) 假阳
* 缓存预热
  redis重启之前，写一个接口，热点数据先放缓存，再启动服务
* 加锁释放锁不是一个线程
  A拿到锁，设置过期时间3秒，3秒没执行完锁也会被释放，用户不知道，在第四秒unlock，就会出现一个情况，当B在3秒那一刻拿到锁了，结果A就会把B的锁释放掉
  解决方案：value存入uuid线程唯一标识，释放锁的时候判断标识，get del使用Lua保证原子操作。就是看看这个uuid是不是自己的，是自己的才删除
* setnx不可重入，锁不释放不能在再次setnx
  解决方式，redisson(AQS, 计数)
  可重入：线程在持有锁的情况下在此请求加锁，不会被阻塞或者死锁。通过对客户端Set进行包装，使用线程的THreadlocal变量存储当前持有锁的计数，来实现可重入
  AQS内部维护了一个状态变量state，和一个等待队列，用于控制线程对共享资源的访问。计数是表示当前同步器允许或者阻塞多少个线程访问共享资源
* redis事务中，watch监控每一个key,如果key发生变化，会将事务取消
  1. watch 一下，multi执行，事务开始。muti将客户端状态的flags属性打开redis_muti标识完成
  2. 命令入队：当客户端切换到事务态，服务器根据收到的命令执行操作，如multi, exec, watch, discard就立即执行，否则将命令入队，向客户端返回queued回复
  3. 事务执行：客户端发送exec命令，服务器执行。如果客户端状态的flags属性不包含redis_multi标识或者包含redis_dirty_cas或者redis_dirty_exec标识，取消事务的执行。否则客户端就处于事务状态，服务器遍历客户端的事务队列，然后执行命令
* watch 是一个乐观锁，可以为redis提供 check-and-set （CAS）行为。可以监控一个或多个key。一旦有key被修改或删除，事务就不会执行，监控一直持续到exec命令
* discard 客户端清空事务队列，放弃执行事务，客户端退出事务状态
* unwatch可以取消监控
* 悲观锁
  认为线程安全问题一定会存在，因此操作之前先拿锁，确保线程串行执行，如synchronized、lock。竟然多线程并发有安全问题，那就不要并发了呀
* 乐观锁
  认为线程问题不一定会发生，因此不加锁，只是在更新数据时去判断有没有其他线程对数据做了修改。如果没有修改就认为是安全的，自己才更新数据。如果发现了安全问题，此时可以重试或异常
  乐观锁怎么判断被修改过？？
  1. 版本号法：给数据加上version字段，每次数据做了修改，版本号+1.
  2. CAS法：直接根据库存又没有变去判断就行
* nginx负载均衡
  1. 轮询
  2. 加权轮询
  3. 最少连接
  4. IP哈希
  5. fair: 根据后端服务器的响应事件和负载情况动态分配请求，可以实现更加均衡的负载，适用于后端服务器性能差异较大或者负载波动较大的场景
  6. url_hash：根据请求的URL计算哈希值，并将请求分配给对应服务器。可以保证同一个URL始终分给同一个服务器，有利于缓存利用。适用静态资源或者文件下载的场景
  7. consistent_hash：根据客户端IP或者其他自定义参数计算哈希值，并将请求分配给对应的服务器。可以保证同一个客户端总是访问同一个服务器，有利于会话保持和缓存利用。适用于粘滞性或者一致性的场景---购物车信息